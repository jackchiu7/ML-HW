{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standardization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Centered and Normalized Data')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "import numpy as np\n",
    "\n",
    "samples, labels = load_wine(return_X_y = True)\n",
    "#print(labels)\n",
    "\n",
    "means = np.array([])\n",
    "stDev = np.array([])\n",
    "for i in range(0,len(samples[0])):\n",
    "    means = np.append(means, sum(samples[:,i]/float(len(samples))))\n",
    "    stDev= np.append(stDev, np.std(samples[:,i]))\n",
    "\n",
    "samplesCentered = samples - means\n",
    "covX = np.cov(samplesCentered.transpose())\n",
    "vals, vects = np.linalg.eig(covX)\n",
    "inds = vals.argsort()[-2:][::-1]    # 2 dimensions\n",
    "\n",
    "#print(vals)\n",
    "\n",
    "u1 = np.reshape(vects[:,inds[0]],(13,1))\n",
    "u2 = np.reshape(vects[:,inds[1]],(13,1))\n",
    "U = np.concatenate((u1,u2),1)\n",
    "#print(\"Matrix U\")\n",
    "#print(U)\n",
    "\n",
    "#print(U.shape)\n",
    "#print(samples.shape)\n",
    "\n",
    "samples2d = np.matmul(samplesCentered, U)\n",
    "#samples2dT = samples2d.transpose()\n",
    "\n",
    "fig, ax = plt.subplots(2,1,figsize = (5,10))\n",
    "i = 0\n",
    "for sample in samples2d:\n",
    "    if labels[i] == 0:\n",
    "        ax[0].plot(sample[0],sample[1], 'rs')\n",
    "    elif labels[i] == 1:\n",
    "        ax[0].plot(sample[0],sample[1], 'g^')\n",
    "    elif labels[i] ==2:\n",
    "        ax[0].plot(sample[0],sample[1], 'bo')\n",
    "    i += 1\n",
    "\n",
    "ax[0].set_title('Centered Data')\n",
    "#print(samples2d.shape)\n",
    "\n",
    "samplesUniform = samplesCentered\n",
    "#print(len(samplesUniform))\n",
    "for i in range(0,len(samplesUniform)):\n",
    "    samplesUniform[i] = np.divide(samplesUniform[i],stDev)\n",
    "\n",
    "\n",
    "covX = np.cov(samplesUniform.transpose())\n",
    "vals, vects = np.linalg.eig(covX)\n",
    "inds = vals.argsort()[-2:][::-1]    # 2 dimensions\n",
    "\n",
    "u1 = np.reshape(vects[:,inds[0]],(13,1))\n",
    "u2 = np.reshape(vects[:,inds[1]],(13,1))\n",
    "U = np.concatenate((u1,u2),1)\n",
    "samples2dU = np.matmul(samplesCentered, U)\n",
    "\n",
    "i =0\n",
    "for sample in samples2dU:\n",
    "    if labels[i] == 0:\n",
    "        ax[1].plot(sample[0],sample[1], 'rs')\n",
    "    elif labels[i] == 1:\n",
    "        ax[1].plot(sample[0],sample[1], 'g^')\n",
    "    elif labels[i] ==2:\n",
    "        ax[1].plot(sample[0],sample[1], 'bo')\n",
    "    i += 1\n",
    "\n",
    "ax[1].set_title('Centered and Normalized Data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As given by the two plots above, using centralized and normalized data provides for significantly better classification of the data. In the first graph, the centered data causes there to be significant overlap between the blue circles and green triangles. In contrast, there is very slight overlap when using the normalized and centered data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB as Gauss\n",
    "import random\n",
    "import math\n",
    "\n",
    "def prob(x, mean, stdev): # Using Gaussian Distribution\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "def classProb(classAttributes, unknown): #Get the probabilities that an unknown vector of features is each class\n",
    "    probabilities = [1.0,1.0,1.0]\n",
    "    for attr in classAttributes:\n",
    "        for i in range(len(attr)):\n",
    "            mean = attr[i][0]\n",
    "            std = attr[i][0]\n",
    "            probabilities[i] *= prob(unknown[i], mean, std)\n",
    "    return probabilities\n",
    "\n",
    "def getClass(classAttributes, unknown):\n",
    "    probs = classProb(classAttributes, unknown)\n",
    "    return probs.index(max(probs))\n",
    "    \n",
    "def getAttr(data, labels):\n",
    "    class1 = []\n",
    "    class2 = []\n",
    "    class3 = []\n",
    "\n",
    "    for i in range(0,len(labels)):\n",
    "        if labels[i] == 0:\n",
    "            class1.append(data[i])        \n",
    "        elif labels[i] ==1:\n",
    "            class2.append(data[i])\n",
    "        elif labels[i] ==2:\n",
    "            class3.append(data[i])\n",
    "            \n",
    "    classAttributes = [] #(mean, std)\n",
    "    class1 = np.array(class1)\n",
    "    class2 = np.array(class2)\n",
    "    class3 = np.array(class3)\n",
    "\n",
    "    for classes in [class1, class2, class3]:\n",
    "        means = np.array([])\n",
    "        stDev = np.array([])\n",
    "        for i in range(0,len(classes[0])):\n",
    "            means = np.append(means, sum(classes[:,i]/float(len(classes))))\n",
    "            stDev= np.append(stDev, np.std(classes[:,i]))\n",
    "        \n",
    "        classAttributes.append((means, stDev))\n",
    "    \n",
    "    return classAttributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors given by using Naive Bayes for K = 5\n",
      "Centered Data:  [17, 14, 13, 12, 18]   Mean: 14.8    Variance: 5.36\n",
      "Standardized Data: [17, 14, 13, 12, 18]   Mean: 14.8    Variance: 5.36\n",
      "Using scikitlearn Gaussian:  [0, 0, 0, 1, 0]   Mean: 0.2    Variance: 0.16000000000000003\n"
     ]
    }
   ],
   "source": [
    "samplesCentered = samples2d\n",
    "samplesUniform = samples2dU\n",
    "shuffleIndex = random.sample(range(178), 178)\n",
    "samplesCopy = samples\n",
    "samplesUCopy = samplesUniform\n",
    "samplesCCopy = samplesCentered\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    samples[i] = samplesCopy[shuffleIndex[i]]\n",
    "    samplesCentered[i] = samplesCCopy[shuffleIndex[i]]\n",
    "    samplesUniform[i] = samplesUCopy[shuffleIndex[i]]\n",
    "    labels[i] = labels[shuffleIndex[i]]\n",
    "\n",
    "\n",
    "labelsList = []\n",
    "samplesList = []\n",
    "samplesCList = []\n",
    "samplesUList = []\n",
    "indices = [0, 35, 70, 106, 142, 178]\n",
    "for i in range(len(indices)-1):\n",
    "    ind1 = indices[i]\n",
    "    ind2 = indices[i+1]\n",
    "    labelsList.append(labels[ind1:ind2])\n",
    "    samplesList.append(samples[ind1:ind2])\n",
    "    samplesCList.append(samplesCentered[ind1:ind2])\n",
    "    samplesUList.append(samplesUniform[ind1:ind2])\n",
    "    \n",
    "resultsC = []\n",
    "resultsU = []\n",
    "resultsG = []\n",
    "clf = Gauss()\n",
    "for i in range(0,5): # have each partitioned data be validation\n",
    "    samplesCListTrain = samplesCList.copy()\n",
    "    samplesUListTrain = samplesUList.copy()\n",
    "    labelsTrain = labelsList.copy()\n",
    "    valC = samplesCListTrain.pop(i)\n",
    "    valU = samplesUListTrain.pop(i)\n",
    "    valLabels = labelsTrain.pop(i)\n",
    "    \n",
    "    predictionsC = []\n",
    "    predictionsU = []\n",
    "    predictionsG = []\n",
    "    trainC = np.concatenate(samplesCListTrain)\n",
    "    trainU = np.concatenate(samplesUListTrain)\n",
    "    trainLabels = np.concatenate(labelsTrain)\n",
    "    \n",
    "    attrCTest = getAttr(trainC, trainLabels)\n",
    "    attrUTest = getAttr(trainU, trainLabels)\n",
    "    clf.fit(trainU, trainLabels)\n",
    "    \n",
    "    #Using 0-1 loss to determine errors\n",
    "    errorC = 0\n",
    "    errorU = 0\n",
    "    errorG = 0 \n",
    "    for i in range(len(valC)):\n",
    "        predictC = getClass(attrCTest, valC[i])\n",
    "        predictU = getClass(attrUTest, valU[i])\n",
    "        predictG = clf.predict(valU[i].reshape((1,len(valU[i]))))\n",
    "\n",
    "        if predictC != int(valLabels[i]):\n",
    "            errorC += 1\n",
    "        if predictU != int(valLabels[i]):\n",
    "            errorU += 1\n",
    "        if predictG != int(valLabels[i]):\n",
    "            errorG += 1\n",
    "    \n",
    "    resultsC.append(errorC)\n",
    "    resultsU.append(errorU)\n",
    "    resultsG.append(errorG)\n",
    "     \n",
    "\n",
    "print('Errors given by using Naive Bayes for K = 5')\n",
    "print('Centered Data: ', resultsC, '  Mean:', np.mean(resultsC), '   Variance:', np.var(resultsC))\n",
    "print('Standardized Data:', resultsU, '  Mean:', np.mean(resultsU), '   Variance:', np.var(resultsU))\n",
    "print('Using scikitlearn Gaussian: ', resultsG, '  Mean:', np.mean(resultsG), '   Variance:', np.var(resultsG))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second part, the Naive Bayes Classification was created by calculating the probability that each sample's features is a certain classes feature. From there, the entire proability that a sample is in a certain class can be determined. Based on the ouput and using 0-1 loss to determine the error, the mean and variance of the error can be found between the 5 different validation sets used for K=5 cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
